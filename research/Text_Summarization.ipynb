{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIRU268dJofR",
        "outputId": "1bb164f3-c092-4791-8362-d70ca3f31fd3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'nvidia-smi' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wsI9VlRhKb5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  DEPRECATION: Building 'rouge_score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge_score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt-31qf0Kb77",
        "outputId": "c4344a94-30c2-4e10-8453-28cb9422a783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (1.7.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from accelerate) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from accelerate) (2.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from accelerate) (0.31.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n",
            "Found existing installation: transformers 4.51.3\n",
            "Uninstalling transformers-4.51.3:\n",
            "  Successfully uninstalled transformers-4.51.3\n",
            "Found existing installation: accelerate 1.7.0\n",
            "Uninstalling accelerate-1.7.0:\n",
            "  Successfully uninstalled accelerate-1.7.0\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting accelerate\n",
            "  Using cached accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from transformers) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: psutil in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from accelerate) (2.7.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
            "Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "Using cached accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
            "Installing collected packages: accelerate, transformers\n",
            "\n",
            "   ---------------------------------------- 0/2 [accelerate]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   -------------------- ------------------- 1/2 [transformers]\n",
            "   ---------------------------------------- 2/2 [transformers]\n",
            "\n",
            "Successfully installed accelerate-1.7.0 transformers-4.51.3\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade accelerate\n",
        "!pip uninstall -y transformers accelerate\n",
        "!pip install transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA0d-NC1Q7bw",
        "outputId": "555912cb-4b9c-4661-b0f9-bf61fbb9064e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from evaluate) (2.2.6)\n",
            "Requirement already satisfied: dill in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from evaluate) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from evaluate) (0.31.2)\n",
            "Requirement already satisfied: packaging in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (3.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
            "Requirement already satisfied: colorama in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (2.7.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==2.1.2 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (2.1.2)\n",
            "Requirement already satisfied: torchvision in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (0.16.2)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (2.1.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch==2.1.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch==2.1.2) (4.13.2)\n",
            "Requirement already satisfied: sympy in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch==2.1.2) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch==2.1.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch==2.1.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch==2.1.2) (2025.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torchvision) (2.2.6)\n",
            "Requirement already satisfied: requests in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torchvision) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from jinja2->torch==2.1.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests->torchvision) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests->torchvision) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests->torchvision) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests->torchvision) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from sympy->torch==2.1.2) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.1.2 torchvision torchaudio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch==2.1.2 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (2.1.2)\n",
            "Requirement already satisfied: torchvision in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (0.16.2)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (2.1.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch==2.1.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch==2.1.2) (4.13.2)\n",
            "Requirement already satisfied: sympy in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch==2.1.2) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch==2.1.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch==2.1.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torch==2.1.2) (2025.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torchvision) (2.2.6)\n",
            "Requirement already satisfied: requests in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torchvision) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from jinja2->torch==2.1.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests->torchvision) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests->torchvision) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests->torchvision) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from requests->torchvision) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gurudas n vijayan\\anaconda3\\envs\\hfacetexts\\lib\\site-packages (from sympy->torch==2.1.2) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.1.2 torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
            "    self.io_loop.start()\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\asyncio\\events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
            "    await result\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"C:\\Users\\GURUDAS N VIJAYAN\\AppData\\Local\\Temp\\ipykernel_25440\\2440548420.py\", line 1, in <module>\n",
            "    import torch\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\torch\\__init__.py\", line 1382, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\torch\\functional.py\", line 7, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1.2+cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFaghw6KKb-r",
        "outputId": "31809956-6bd7-4b52-90e5-2517ff4d226e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to C:\\Users\\GURUDAS N\n",
            "[nltk_data]     VIJAYAN\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline, set_seed\n",
        "from datasets import load_dataset, load_from_disk\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "from evaluate import load as load_metric\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNsNn1hyKcBT",
        "outputId": "20da8795-24a1-461d-8aab-d274d2e5da6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error while downloading from https://cdn-lfs.hf.co/google/pegasus-cnn_dailymail/89463bc493ce252a2919b01ad3d00bae933f079d0cf279cf96c33312dc63a249?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1747563611&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NzU2MzYxMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9nb29nbGUvcGVnYXN1cy1jbm5fZGFpbHltYWlsLzg5NDYzYmM0OTNjZTI1MmEyOTE5YjAxYWQzZDAwYmFlOTMzZjA3OWQwY2YyNzljZjk2YzMzMzEyZGM2M2EyNDk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=Om9USgQgXOs7R%7EW5Kw19ngSdeCRG3kWV3WNNO6RHTJp%7EN921cA9HGT4GjwH4azbUUoPYZfrtML0Vgf8vVzes8Vl31FfxFUaDwoIMru4it234datzCyHf958Xx6rcDPxBfvlLRVJEF1QetlfneOYuZCc2J9qaWqM%7EkFKLB-lL%7EZo2DVVK77D27MzG7xaWX7F7%7EeYTJ9oOObAxI61NOCn7AQY%7EUs%7EiGHu52rnAptlibXYXHwJhtoAVxQvujq8VrfjD%7EU7TDaV2K2kdkDl7ZwBMDJoVO7p1MGkWAcx4NvG4l8WWpzsTsSHSTE5CitQ%7EFxNIpOxdIAAuNUFwJzZpd4uv4Q__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
            "Trying to resume download...\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model_ckpt = 'google/pegasus-cnn_dailymail'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "\n",
        "model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pGkYw5vwKcLb",
        "outputId": "4e29b6e5-5d94-4986-f386-77894ff6101b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHvgSuU6KcOH",
        "outputId": "3368538a-0454-49a4-ded5-eeebccefe337"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# download and unzip data\n",
        "\n",
        "!wget https://github.com/dystinktbeatz/Text-summarizer-project/raw/refs/heads/main/samsum_dataset_G.zip\n",
        "!unzip summarizer-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Downloaded successfully!\n",
            "✅ Unzipped successfully!\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Download the file\n",
        "url = \"https://github.com/dystinktbeatz/Text-summarizer-project/raw/refs/heads/main/samsum_dataset_G.zip\"\n",
        "local_zip_path = \"samsum_dataset_G.zip\"\n",
        "\n",
        "urllib.request.urlretrieve(url, local_zip_path)\n",
        "print(\"✅ Downloaded successfully!\")\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(local_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"extracted_data\")  # choose your target folder\n",
        "\n",
        "print(\"✅ Unzipped successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['01_data_ingestion.ipynb', '02_data_validation.ipynb', 'extracted_data', 'samsum_dataset_G.zip', 'Text_Summarization.ipynb', 'trials.ipynb']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(os.listdir())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['samsum-test.csv', 'samsum-train.csv', 'samsum-validation.csv', 'samsum_dataset']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.listdir(\"extracted_data\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is it a file? False\n",
            "Is it a directory? True\n",
            "Contents (if directory): ['dataset_dict.json', 'test', 'train', 'validation']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "path = \"extracted_data/samsum_dataset\"\n",
        "print(\"Is it a file?\", os.path.isfile(path))\n",
        "print(\"Is it a directory?\", os.path.isdir(path))\n",
        "print(\"Contents (if directory):\", os.listdir(path) if os.path.isdir(path) else \"N/A\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLMDVvlfKcQ5",
        "outputId": "2ed33013-f7d2-44a0-d2a2-74492f49d101"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary'],\n",
              "        num_rows: 14732\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary'],\n",
              "        num_rows: 819\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary'],\n",
              "        num_rows: 818\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_from_disk\n",
        "dataset_samsum = load_from_disk(\"extracted_data/samsum_dataset\")\n",
        "dataset_samsum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_mQgOYXKcWX",
        "outputId": "8db06dbd-eb69-4efe-ea91-822f29c5e8d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split lengths: [14732, 819, 818]\n",
            "Features: ['id', 'dialogue', 'summary']\n",
            "\n",
            "Dialogue:\n",
            "Eric: MACHINE!\n",
            "Rob: That's so gr8!\n",
            "Eric: I know! And shows how Americans see Russian ;)\n",
            "Rob: And it's really funny!\n",
            "Eric: I know! I especially like the train part!\n",
            "Rob: Hahaha! No one talks to the machine like that!\n",
            "Eric: Is this his only stand-up?\n",
            "Rob: Idk. I'll check.\n",
            "Eric: Sure.\n",
            "Rob: Turns out no! There are some of his stand-ups on youtube.\n",
            "Eric: Gr8! I'll watch them now!\n",
            "Rob: Me too!\n",
            "Eric: MACHINE!\n",
            "Rob: MACHINE!\n",
            "Eric: TTYL?\n",
            "Rob: Sure :)\n",
            "\n",
            "Summary:\n",
            "Eric and Rob are going to watch a stand-up on youtube.\n"
          ]
        }
      ],
      "source": [
        "split_lengths = [len(dataset_samsum[split])for split in dataset_samsum]\n",
        "\n",
        "print(f'Split lengths: {split_lengths}')\n",
        "print(f'Features: {dataset_samsum[\"train\"].column_names}')\n",
        "print(\"\\nDialogue:\")\n",
        "\n",
        "print(dataset_samsum['test'][1]['dialogue'])\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "print(dataset_samsum['test'][1]['summary'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DPAwyfWFKcY5"
      },
      "outputs": [],
      "source": [
        "def convert_examples_to_features(example_batch):\n",
        "    input_encodings = tokenizer(example_batch['dialogue'] , max_length = 1024, truncation = True )\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        target_encodings = tokenizer(example_batch['summary'], max_length = 128, truncation = True )\n",
        "\n",
        "    return {\n",
        "        'input_ids' : input_encodings['input_ids'],\n",
        "        'attention_mask': input_encodings['attention_mask'],\n",
        "        'labels': target_encodings['input_ids']\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "e105d0ac42904c84980266c792bc0c54",
            "9afae87eb0564af2bf65da3ce75ccb3c",
            "2ff011cf6ca24a869309c69fd25881a8",
            "e0777a8115cc4ca7932147075344be9a",
            "7602ac64e320425095c2a986fd5bcae0",
            "42f28a04b1414cb9857e26e6c9d574fc",
            "ff32bf0ec066401086ab62c3d3a520f3",
            "a4556f23ce8949f0818232eb74e52cb3",
            "f6121bb0869c41649ff900331e4c53b0",
            "f827360e3fbc4e1a9ab9f54bbbf24f3f",
            "396c47d2abb24762a47f9db2dee409fd"
          ]
        },
        "id": "3_BXvk4MKcb0",
        "outputId": "a363155b-677b-4196-8deb-79f0e793f717"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map: 100%|██████████| 14732/14732 [00:01<00:00, 7872.84 examples/s]\n",
            "Map: 100%|██████████| 819/819 [00:00<00:00, 8297.69 examples/s]\n",
            "Map: 100%|██████████| 818/818 [00:00<00:00, 8138.37 examples/s]\n"
          ]
        }
      ],
      "source": [
        "dataset_samsun_pt = dataset_samsum.map(convert_examples_to_features, batched = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "VVW1THxQKcej"
      },
      "outputs": [],
      "source": [
        "#  Training\n",
        "\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "K3NpdZTkKchh"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "trainer_args = TrainingArguments(\n",
        "    output_dir='pegasus-samsum',\n",
        "    num_train_epochs=1,\n",
        "    warmup_steps=500,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    #evaluation_strategy='epoch',\n",
        "    #logging_delay=500,\n",
        "    save_steps=1e6,\n",
        "    gradient_accumulation_steps=16,\n",
        "    #no_deprecation_warning=True,\n",
        "    report_to=\"none\"\n",
        "    #save_total_limit=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdZsXdNEKcmo",
        "outputId": "0dae0987-f3e3-40be-9fee-7491202073ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\GURUDAS N VIJAYAN\\AppData\\Local\\Temp\\ipykernel_25440\\1708947673.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "# Define a Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model_pegasus,\n",
        "    args=trainer_args,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=seq2seq_data_collator,\n",
        "    train_dataset=dataset_samsun_pt['test'], #!!! always use 'train' here. test is used because the size is small here\n",
        "    eval_dataset=dataset_samsun_pt['validation']\n",
        "\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "F0ragh1qKcqA",
        "outputId": "22b0c777-204a-4b7a-b8ff-03bd9d068dbc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [51/51 34:30, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.110100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.046600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>3.161200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.989800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.852400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\GURUDAS N VIJAYAN\\anaconda3\\envs\\HFaceTextS\\lib\\site-packages\\transformers\\modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=51, training_loss=3.0227330572464886, metrics={'train_runtime': 2114.0149, 'train_samples_per_second': 0.387, 'train_steps_per_second': 0.024, 'total_flos': 313450454089728.0, 'train_loss': 3.0227330572464886, 'epoch': 0.9963369963369964})"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Tn1rfO0WKcsQ"
      },
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "\n",
        "def generate_batch_sized_chunks(list_of_elements, batch_size):\n",
        "    \"\"\"split the dataset into smaller batches that we can process simultaneously\n",
        "    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
        "    for i in range(0, len(list_of_elements), batch_size):\n",
        "        yield list_of_elements[i : i + batch_size]\n",
        "\n",
        "def calculate_metric_on_test_ds(dataset, metric, model, tokenizer,\n",
        "                               batch_size=16, device=device,\n",
        "                               column_text=\"article\",\n",
        "                               column_summary=\"highlights\"):\n",
        "    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n",
        "    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n",
        "\n",
        "    for article_batch, target_batch in tqdm(\n",
        "        zip(article_batches, target_batches), total=len(article_batches)):\n",
        "\n",
        "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n",
        "                        padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
        "                                   attention_mask=inputs[\"attention_mask\"].to(device),\n",
        "                                          length_penalty=0.8, num_beams=8, max_length=128)\n",
        "        '''parameter for length penalty ensures that the model does not generate sequences that are too long.'''\n",
        "\n",
        "        # Finally, we decode the generated texts,\n",
        "        # replace the  token, and add the decoded texts with the reference to the metric.\n",
        "\n",
        "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
        "                                clean_up_tokenization_spaces=True)\n",
        "               for s in summaries]\n",
        "\n",
        "        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n",
        "\n",
        "\n",
        "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
        "\n",
        "        #Finally compute and return the ROUGE scores\n",
        "        score = metric.compute()\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "GEfX49bnKcvD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading builder script: 100%|██████████| 6.27k/6.27k [00:00<?, ?B/s]\n"
          ]
        }
      ],
      "source": [
        "rouge_names = [\"rouge1\",\"rouge2\",\"rougeL\",\"rougeeLsum\"]\n",
        "rouge_metric  = load_metric('rouge')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'])\n"
          ]
        }
      ],
      "source": [
        "print(score.keys())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rouge_names = ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [03:16<00:00, 39.37s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>rougeLsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pegasus</th>\n",
              "      <td>0.036334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.036334</td>\n",
              "      <td>0.036334</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           rouge1  rouge2    rougeL  rougeLsum\n",
              "pegasus  0.036334     0.0  0.036334   0.036334"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score = calculate_metric_on_test_ds(\n",
        "    dataset_samsum['test'][0:10],\n",
        "    rouge_metric,\n",
        "    trainer.model,\n",
        "    tokenizer,\n",
        "    batch_size=2,\n",
        "    column_text='dialogue',\n",
        "    column_summary='summary'\n",
        ")\n",
        "\n",
        "rouge_names = ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
        "\n",
        "rouge_dict = dict((rn, score[rn]) for rn in rouge_names)\n",
        "\n",
        "pd.DataFrame(rouge_dict, index=['pegasus'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "vJP-VUofsxus"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [02:57<00:00, 35.46s/it]\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'rougeeLsum'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[38], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m score \u001b[38;5;241m=\u001b[39m calculate_metric_on_test_ds(\n\u001b[0;32m      2\u001b[0m     dataset_samsum[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      3\u001b[0m     rouge_metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     column_summary\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m rouge_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrouge_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(rouge_dict, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpegasus\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "Cell \u001b[1;32mIn[38], line 11\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m score \u001b[38;5;241m=\u001b[39m calculate_metric_on_test_ds(\n\u001b[0;32m      2\u001b[0m     dataset_samsum[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      3\u001b[0m     rouge_metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     column_summary\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m rouge_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((rn, \u001b[43mscore\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrn\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m rn \u001b[38;5;129;01min\u001b[39;00m rouge_names)\n\u001b[0;32m     13\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(rouge_dict, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpegasus\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "\u001b[1;31mKeyError\u001b[0m: 'rougeeLsum'"
          ]
        }
      ],
      "source": [
        "score = calculate_metric_on_test_ds(\n",
        "    dataset_samsum['test'][0:10],\n",
        "    rouge_metric,\n",
        "    trainer.model,\n",
        "    tokenizer,\n",
        "    batch_size=2,\n",
        "    column_text='dialogue',\n",
        "    column_summary='summary'\n",
        ")\n",
        "\n",
        "rouge_dict = dict((rn, score[rn]) for rn in rouge_names)\n",
        "\n",
        "pd.DataFrame(rouge_dict, index=[f'pegasus'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "n5uxbHvisxr3"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "\n",
        "model_pegasus.save_pretrained(\"pegasus-samsum-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "f0sd3m7Usxo_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('tokenizer\\\\tokenizer_config.json',\n",
              " 'tokenizer\\\\special_tokens_map.json',\n",
              " 'tokenizer\\\\spiece.model',\n",
              " 'tokenizer\\\\added_tokens.json',\n",
              " 'tokenizer\\\\tokenizer.json')"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save tokenizer\n",
        "tokenizer.save_pretrained(\"tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"tokenizer\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "yDNO7i8_sxjp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "Your max_length is set to 128, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dialogue:\n",
            "Hannah: Hey, do you have Betty's number?\n",
            "Amanda: Lemme check\n",
            "Hannah: <file_gif>\n",
            "Amanda: Sorry, can't find it.\n",
            "Amanda: Ask Larry\n",
            "Amanda: He called her last time we were at the park together\n",
            "Hannah: I don't know him well\n",
            "Hannah: <file_gif>\n",
            "Amanda: Don't be shy, he's very nice\n",
            "Hannah: If you say so..\n",
            "Hannah: I'd rather you texted him\n",
            "Amanda: Just text him 🙂\n",
            "Hannah: Urgh.. Alright\n",
            "Hannah: Bye\n",
            "Amanda: Bye bye\n",
            "\n",
            "Reference Summary:\n",
            "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n",
            "\n",
            "Model Summary:\n",
            "Amanda: Ask Larry Amanda: He called her last time we were at the park together .<n>Hannah: I'd rather you texted him .<n>Amanda: Just text him .\n"
          ]
        }
      ],
      "source": [
        "#Prediction\n",
        "\n",
        "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n",
        "\n",
        "sample_text = dataset_samsum[\"test\"][0][\"dialogue\"]\n",
        "\n",
        "reference = dataset_samsum[\"test\"][0][\"summary\"]\n",
        "\n",
        "pipe = pipeline(\"summarization\", model=\"pegasus-samsum-model\",tokenizer=tokenizer)\n",
        "\n",
        "print(\"Dialogue:\")\n",
        "print(sample_text)\n",
        "\n",
        "print(\"\\nReference Summary:\")\n",
        "print(reference)\n",
        "\n",
        "print(\"\\nModel Summary:\")\n",
        "print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D92nK3SpsxYu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VK1Xvw7sxV4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzbgnjapsxS_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuDNX64esxQX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raqnwKttsxNi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuTIzISRsxCN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "HFaceTextS",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ff011cf6ca24a869309c69fd25881a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4556f23ce8949f0818232eb74e52cb3",
            "max": 819,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6121bb0869c41649ff900331e4c53b0",
            "value": 819
          }
        },
        "396c47d2abb24762a47f9db2dee409fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42f28a04b1414cb9857e26e6c9d574fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7602ac64e320425095c2a986fd5bcae0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9afae87eb0564af2bf65da3ce75ccb3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42f28a04b1414cb9857e26e6c9d574fc",
            "placeholder": "​",
            "style": "IPY_MODEL_ff32bf0ec066401086ab62c3d3a520f3",
            "value": "Map: 100%"
          }
        },
        "a4556f23ce8949f0818232eb74e52cb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0777a8115cc4ca7932147075344be9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f827360e3fbc4e1a9ab9f54bbbf24f3f",
            "placeholder": "​",
            "style": "IPY_MODEL_396c47d2abb24762a47f9db2dee409fd",
            "value": " 819/819 [00:00&lt;00:00, 1480.97 examples/s]"
          }
        },
        "e105d0ac42904c84980266c792bc0c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9afae87eb0564af2bf65da3ce75ccb3c",
              "IPY_MODEL_2ff011cf6ca24a869309c69fd25881a8",
              "IPY_MODEL_e0777a8115cc4ca7932147075344be9a"
            ],
            "layout": "IPY_MODEL_7602ac64e320425095c2a986fd5bcae0"
          }
        },
        "f6121bb0869c41649ff900331e4c53b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f827360e3fbc4e1a9ab9f54bbbf24f3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff32bf0ec066401086ab62c3d3a520f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
